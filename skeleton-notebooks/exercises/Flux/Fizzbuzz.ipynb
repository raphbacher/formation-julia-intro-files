{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Solve the Fizzbuzz problem with Flux\n",
    "Inspired by \"Fizz Buzz in Tensorflow\" blog by Joel Grus\n",
    "http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/\n",
    "\n",
    "## Loading libs \n",
    "Use Flux and Test\n",
    "If you don't have Flux install it (Test is included in the standard library)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Data preparation\n",
    "Create a `fizzbuzz` function that takes an `Int` `x` and return `fizzbuzz` if `x` is divisible by 3 and 5, `fizz` if `x` divisible by 3, `buzz` if `x` divisible by 5, and return `else` in other cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Create the dataset\n",
    "First create a list LABELS that stores our different targets (\"fizz\", \"buzz\", \"fizzbuzz\", \"else\")\n",
    "Then generate a vector `raw_x` of the first 100 integers and apply `fizzbuzz` to get the outputs in `raw_y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Feature engineering\n",
    "Define a function `features(x)` that takes an int and return the list (as floats) of modulo by 3, 5 and 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Try to apply it to our vector raw_x and find a way to get a 2d-array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Extract features from `raw_x` to `X `.\n",
    "Build the output `y` from `raw_y` with `onehotbatch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Create the model\n",
    "We will combine (with `Chain`) two dense neural layer (`Dense`) and use the `softmax` function.\n",
    "Our first layer has the three modulo as input and has 10 neurons. The second layer takes these 10 neurons and return the probabilities for the 4 cases (buzz, fizz, fizzbuzz, else)\n",
    "\n",
    "We will use the crossentry as a loss function and `ADAM` as optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Main function\n",
    "Create a function `deepbuzz` that takes a number `x`, applies the model `m` on the features of `x` and return the most probable label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Monitor function \n",
    "\n",
    "Create a function `monitor(e)` that takes an iteration number, print the loss and and the current value of `deepbuzz` for some inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Train\n",
    "We are now ready to train our model. \n",
    "Try for example 1000 runs and monitor every 50 iterations.\n",
    "You will need the `train!` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now predict on a new data with `predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".jl",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Julia 1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
